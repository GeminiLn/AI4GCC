{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.chdir(os.getcwd()+\"/climate-cooperation-competition\")\n",
    "_ROOT = os.getcwd()\n",
    "!pip install -r requirements.txt\n",
    "!pip install rl_warp_drive==1.7.0 # For troubleshooting, please refer to https://github.com/salesforce/warp-drive\n",
    "!pip install ray[rllib]==1.0.0\n",
    "!pip install codecarbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge ray[rllib]==1.0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "_ROOT = os.getcwd()\n",
    "sys.path.append(_ROOT+\"/scripts\")\n",
    "sys.path = [os.path.join(_ROOT, \"/scripts\")] + sys.path\n",
    "\n",
    "from desired_outputs import desired_outputs\n",
    "from importlib import reload\n",
    "from codecarbon import EmissionsTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PUBLIC_REPO_DIR = d:\\Users\\Duo\\Documents\\GitHub\\AI4GCC\n",
      "Using _PRIVATE_REPO_DIR = d:\\Users\\Duo\\Documents\\GitHub\\private-repo-clone\n",
      "WARNING:tensorflow:From d:\\Anaconda3\\envs\\ai4cc\\lib\\site-packages\\tensorflow\\python\\compat\\compat.py:175: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# This is necessary for rllib to get the correct path!\n",
    "os.chdir(_ROOT+\"/scripts\")\n",
    "import train_with_rllib as cpu_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_trainer = reload(cpu_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 20:31:05,720\tERROR worker.py:643 -- Calling ray.init() again after it has already been called.\n",
      "2023-03-21 20:31:05,898\tERROR syncer.py:63 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with RLlib...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 20:31:05,900\tINFO trainer.py:618 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2023-03-21 20:31:06,082\tWARNING util.py:39 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Iter :     1 /     5 **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15032)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15032)\u001b[0m d:\\Anaconda3\\envs\\ai4cc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=15032)\u001b[0m   _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=15032)\u001b[0m d:\\Anaconda3\\envs\\ai4cc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=15032)\u001b[0m   _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=15032)\u001b[0m d:\\Anaconda3\\envs\\ai4cc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=15032)\u001b[0m   _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=15032)\u001b[0m d:\\Anaconda3\\envs\\ai4cc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=15032)\u001b[0m   _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=15032)\u001b[0m d:\\Anaconda3\\envs\\ai4cc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=15032)\u001b[0m   _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "\u001b[2m\u001b[36m(pid=15032)\u001b[0m d:\\Anaconda3\\envs\\ai4cc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=15032)\u001b[0m   np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\u001b[2m\u001b[36m(pid=15032)\u001b[0m WARNING:tensorflow:From d:\\Anaconda3\\envs\\ai4cc\\lib\\site-packages\\tensorflow\\python\\compat\\compat.py:175: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=15032)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=15032)\u001b[0m non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15032)\u001b[0m Using PUBLIC_REPO_DIR = d:\\Users\\Duo\\Documents\\GitHub\\AI4GCC\n",
      "\u001b[2m\u001b[36m(pid=15032)\u001b[0m Using _PRIVATE_REPO_DIR = d:\\Users\\Duo\\Documents\\GitHub\\private-repo-clone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15032)\u001b[0m d:\\Anaconda3\\envs\\ai4cc\\lib\\site-packages\\ray\\rllib\\utils\\torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "\u001b[2m\u001b[36m(pid=15032)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode_reward_mean: 105.0274016106402\n",
      "********** Iter :     2 /     5 **********\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Anaconda3\\envs\\ai4cc\\lib\\inspect.py\u001b[0m in \u001b[0;36mcurrentframe\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1505\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mframelist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1507\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mcurrentframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1508\u001b[0m     \u001b[1;34m\"\"\"Return the frame of the caller or None if this is not possible.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_getframe\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'ray._raylet.get_py_stack'\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Anaconda3\\envs\\ai4cc\\lib\\inspect.py\", line 1507, in currentframe\n",
      "    def currentframe():\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode_reward_mean: 104.91179328432025\n",
      "********** Iter :     3 /     5 **********\n"
     ]
    }
   ],
   "source": [
    "cpu_trainer_off, cpu_nego_off_ts = cpu_trainer.trainer(negotiation_on=0,  # no negotiation\n",
    "  num_envs=1, \n",
    "  train_batch_size=1024, \n",
    "  num_episodes=300, \n",
    "  lr=0.0005, \n",
    "  model_params_save_freq=5000, \n",
    "  desired_outputs=desired_outputs, # a list of values that the simulator will output\n",
    "  num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_trainer = reload(cpu_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with RLlib...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 20:32:50,256\tINFO services.py:1166 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2023-03-21 20:32:55,519\tERROR syncer.py:63 -- Log sync requires rsync to be installed.\n",
      "2023-03-21 20:32:55,522\tINFO trainer.py:618 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2023-03-21 20:32:55,729\tWARNING util.py:39 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Iter :     1 /    17 **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=32228)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=32228)\u001b[0m d:\\Anaconda3\\envs\\ai4cc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=32228)\u001b[0m   _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=32228)\u001b[0m d:\\Anaconda3\\envs\\ai4cc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=32228)\u001b[0m   _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=32228)\u001b[0m d:\\Anaconda3\\envs\\ai4cc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=32228)\u001b[0m   _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=32228)\u001b[0m d:\\Anaconda3\\envs\\ai4cc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=32228)\u001b[0m   _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=32228)\u001b[0m d:\\Anaconda3\\envs\\ai4cc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=32228)\u001b[0m   _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "\u001b[2m\u001b[36m(pid=32228)\u001b[0m d:\\Anaconda3\\envs\\ai4cc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=32228)\u001b[0m   np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\u001b[2m\u001b[36m(pid=32228)\u001b[0m WARNING:tensorflow:From d:\\Anaconda3\\envs\\ai4cc\\lib\\site-packages\\tensorflow\\python\\compat\\compat.py:175: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=32228)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=32228)\u001b[0m non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=32228)\u001b[0m Using PUBLIC_REPO_DIR = d:\\Users\\Duo\\Documents\\GitHub\\AI4GCC\n",
      "\u001b[2m\u001b[36m(pid=32228)\u001b[0m Using _PRIVATE_REPO_DIR = d:\\Users\\Duo\\Documents\\GitHub\\private-repo-clone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=32228)\u001b[0m d:\\Anaconda3\\envs\\ai4cc\\lib\\site-packages\\ray\\rllib\\utils\\torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "\u001b[2m\u001b[36m(pid=32228)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=32228)\u001b[0m d:\\Users\\Duo\\Documents\\GitHub\\AI4GCC\\rice.py:722: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "\u001b[2m\u001b[36m(pid=32228)\u001b[0m   \"group_disccused_ratio\", np.array(group_ration_all_regions).squeeze(), self.timestep\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode_reward_mean: 65.29402781136064\n",
      "********** Iter :     2 /    17 **********\n",
      "episode_reward_mean: 67.2062916530437\n",
      "********** Iter :     3 /    17 **********\n",
      "episode_reward_mean: 68.61744934360048\n",
      "********** Iter :     4 /    17 **********\n",
      "episode_reward_mean: 68.98365665400976\n",
      "********** Iter :     5 /    17 **********\n",
      "episode_reward_mean: 69.13296984630621\n",
      "********** Iter :     6 /    17 **********\n",
      "episode_reward_mean: 69.91703065129904\n",
      "********** Iter :     7 /    17 **********\n",
      "episode_reward_mean: 70.35941878200578\n",
      "********** Iter :     8 /    17 **********\n",
      "episode_reward_mean: 71.10327489182048\n",
      "********** Iter :     9 /    17 **********\n",
      "episode_reward_mean: 71.45461284993749\n",
      "********** Iter :    10 /    17 **********\n",
      "episode_reward_mean: 72.10483921813929\n",
      "********** Iter :    11 /    17 **********\n",
      "episode_reward_mean: 73.16685899606989\n",
      "********** Iter :    12 /    17 **********\n",
      "episode_reward_mean: 73.98415384164261\n",
      "********** Iter :    13 /    17 **********\n",
      "episode_reward_mean: 75.07292709255591\n",
      "********** Iter :    14 /    17 **********\n",
      "episode_reward_mean: 75.92911937302173\n",
      "********** Iter :    15 /    17 **********\n",
      "episode_reward_mean: 77.8526917298703\n",
      "********** Iter :    16 /    17 **********\n",
      "episode_reward_mean: 78.70342561150238\n",
      "********** Iter :    17 /    17 **********\n",
      "episode_reward_mean: 80.46792149086315\n"
     ]
    }
   ],
   "source": [
    "cpu_trainer_on, cpu_nego_on_ts = cpu_trainer.trainer(negotiation_on=1, # with naive negotiation\n",
    "  num_envs=1, \n",
    "  train_batch_size=1024, \n",
    "  num_episodes=300, \n",
    "  lr=0.0005, \n",
    "  model_params_save_freq=5000, \n",
    "  desired_outputs=desired_outputs, # a list of values that the simulator will output\n",
    "  num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "530.0312107801437"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(grp_on_ts[\"production_all_regions\"][60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392.07232415676117"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(grp_off_ts[\"production_all_regions\"][60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_gpt_on = cpu_nego_on_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_gpt_off = cpu_nego_on_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opt_helper import save, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save({ \"grp_on\":cpu_gpt_on}, \"cpu_qpt_eps300withsaving.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [uncomment below to load]\n",
    "dict_ts = load(\"cpu_qpt_eps300withsaving.pkl\")\n",
    "grp_on_ts = dict_ts[\"grp_on\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.69995177, 0.17463201])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_on_ts[\"global_temperature\"][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89999998, 0.89999998, 0.89999998, 0.89999998, 0.89999998,\n",
       "       0.89999998, 0.89999998, 0.89999998, 0.89999998, 0.89999998,\n",
       "       0.89999998, 0.80000001, 0.89999998, 0.89999998, 0.89999998,\n",
       "       0.89999998, 0.89999998, 0.89999998, 0.89999998, 0.89999998,\n",
       "       0.89999998, 0.89999998, 0.89999998, 0.89999998, 0.89999998,\n",
       "       0.89999998, 0.89999998])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nego_on_ts[\"minimum_mitigation_rate_all_regions\"][60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " dict_ts = load(\"cpu_qpt_eps300.pkl\")\n",
    " grp_off_ts, grp_on_ts = dict_ts[\"grp_off\"], dict_ts[\"grp_on\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "glob(os.path.join(_ROOT,\"Submissions/*.zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21748\\3039533087.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mopt_helper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_training_curve\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_training_curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlog_zip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ROOT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Submissions/*.zip\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplot_training_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Mean episodic reward'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_zip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from opt_helper import get_training_curve, plot_training_curve\n",
    "\n",
    "log_zip = glob(os.path.join(_ROOT,\"Submissions/*.zip\"))[0]\n",
    "plot_training_curve(None, 'Mean episodic reward', log_zip)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('ai4cc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4c2d768bf57f7f360063095d9d320b25509a7d280f9a474cd2b9f1963260e3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
